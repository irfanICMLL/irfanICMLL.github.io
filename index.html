
<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Yifan Liu</title>
	<meta content="Yifan Liu, irfanICMLL.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul { 
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');



</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="YifanLiu" style="float: left; padding-left: .01em; height: 140px;" src="yifan.png" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Yifan Liu</span><br />
<span><strong>PhD candidate</strong></span><br /> 
<span><strong>Email  </strong>: yifan[dot]liu04[at]adelaide[dot]edu[dot]au</span> <br /> 
<span>I am a computer science PhD student at the <a href='https://www.adelaide.edu.au/'>University of Adelaide</a> and supervised by <a href='http://cs.adelaide.edu.au/~chhshen/'>Chunhua Shen</a> .</span>
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>(<a href='https://scholar.google.com/citations?user=ksQ4JnQAAAAJ&hl=zh-CN'>Google scholar</a>)</h2>
<div class="paper">
Before I came to Adelaide, I was a visiting student at <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>MSRA</a> under the supervision of Prof.<a href='https://jingdongwang2017.github.io/'>Jingdong Wang</a>. I got my master degree and my B.Sc. degree at School of <a href = 'asee.buaa.edu.cn'>Automation Science and Electrical Engineering</a> at <a href='https://ev.buaa.edu.cn/'>Beihang University</a> supervised by Prof.<a href='http://dsd.future-lab.cn/members/qin.html'>Zengchang Qin</a>.
<br> <br>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
    <li> July, 2020: Three <a href='https://eccv2020.eu/'>ECCV</a> papers have been accepted. </a> </li>
    <li> Jun, 2020: Our journal paper "Structured Knowledge Distillation for Dense Predcition" has been accepted by TPAMI, and is avaiable online. <a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9115859'>[PDF]</a> </li>
    <li> Feb, 2020: Demo <a href='https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation'>Code</a> of our new work on  <a href='https://arxiv.org/pdf/2002.11433.pdf'>semantic video segmentation</a> has been released. </li>
    <li> Oct, 2019: Training <a href='https://github.com/irfanICMLL/structure_knowledge_distillation'>Code</a> of our structure knowledge distillation has been released. </li>	    
    <li> May, 2019: One <a href='http://iccv2019.thecvf.com//'>ICCV</a> papers have been accepted. </li>
    <li> Mar, 2019: One <a href='2019.thecvf.com/'>CVPR</a> papers have been accepted (Oral:288/5160). </li>
    <li> Feb, 2019: We are the 3nd winner for AI Edge Contest, on <a href='https://signate.jp/competitions/143/leaderboard'>Semantic segmentation </a> (3/90). </li>
    <li> Nov, 2018: Come to Adelaide University for PhD career </li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications</h2>
<div class="paper" id="ECCV2020"><img class="paper" src="papers/ECCV.png" title="Efficient Semantic Video Segmentation with Per-frame Inference" />
<div> <strong>Efficient Semantic Video Segmentation with Per-frame Inference</strong><br />
<strong>Yifan Liu</strong>, Chunhua Shen, Changqian Yu, Jingdong Wang<br />
Arxiv,2020<br /> 
<a href='https://arxiv.org/pdf/2002.11433.pdf'>[PDF]</a>
<a href='https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="TPAMI"><img class="paper" src="papers/pami.png" title="Structured Knowledge Distillation for Dense Prediction" />
<div> <strong>Structured Knowledge Distillation for Dense Prediction</strong><br />
<strong>Yifan Liu</strong>, Changyong Shu, Jingdong Wang, Chunhua Shen<br />
Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2020<br /> 
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9115859'>[PDF]</a>
<a href='https://github.com/irfanICMLL/structure_knowledge_distillation'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="CVPR2019"><img class="paper" src="papers/cvpr.png" title="Structured Knowledge Distillation for Semantic Segmentation" />
<div> <strong>Structured Knowledge Distillation for Semantic Segmentation</strong><br />
<strong>Yifan Liu</strong>, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, Jingdong Wang<br />
Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019, <alert>[oral]</alert><br /> 
<a href='https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.pdf'>[PDF]</a>
<a href='https://github.com/irfanICMLL/structure_knowledge_distillation'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="ICCV2019"><img class="paper" src="papers/iccv2019.png" title="Enforcing geometric constraints of virtual normal for depth prediction" />
<div> <strong>Enforcing geometric constraints of virtual normal for depth prediction</strong><br />
Wei Yin, <strong>Yifan Liu</strong>, Chunhua Shen, Youliang Yan<br />
International Conference on Computer Vision (<strong>ICCV</strong>), 2019,<br /> 
<a href='https://arxiv.org/pdf/1907.12209.pdf'>[PDF]</a>
<a href='https://github.com/YvanYin/VNL_Monocular_Depth_Prediction'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="Arxiv"><img class="paper" src="papers/DiverseDepth.png" title="DiverseDepth: Affine-invariant Depth Prediction Using Diverse Data" />
<div> <strong>DiverseDepth: Affine-invariant Depth Prediction Using Diverse Data</strong><br />
Wei Yin, Xinlong Wang, Chunhua Shen, <strong>Yifan Liu</strong>, Zhi Tian, Songcen Xu, Changming Sun, Dou Renyin<br />
Arxiv,2020<br /> 
<a href='https://arxiv.org/pdf/2002.00569.pdf'>[PDF]</a>
<a href='https://github.com/YvanYin/DiverseDepth'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="PR2019"><img class="paper" src="papers/MobileFAN.jpg" title="MobileFAN: Transferring deep hidden representation for face alignment" />
<div> <strong>MobileFAN: Transferring deep hidden representation for face alignment</strong><br />
Yang Zhao, <strong>Yifan Liu</strong>, Chunhua Shen, Yongsheng Gao, Shengwu Xiong<br />
Pattern Recognition (<strong>PR</strong>), 2019,<br /> 
<a href='https://www.sciencedirect.com/science/article/pii/S0031320319304157?utm_campaign=STMJ_75273_AUTH_SERV_PPUB&utm_medium=email&utm_dgroup=Email1Publishing&utm_acid=-798781226&SIS_ID=-1&dgcid=STMJ_75273_AUTH_SERV_PPUB&CMX_ID=&utm_in=DM620491&utm_source=AC_30&utm_term=Email%201%20Publishing_TLSH_Reminder#fig0005'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>
<div class="paper" id="journals"><img class="paper" src="papers/neurocomputing.png" title="Auto-painter: Cartoon image generation from sketch by using conditional Wasserstein generative adversarial networks" />
<div> <strong>Auto-painter: Cartoon image generation from sketch by using conditional Wasserstein generative adversarial networks</strong><br />
<strong>Yifan Liu</strong>, Zengchang Qin, Tao Wan, Zhenbo Luo  <br />
Neurocomputing (<strong>Neurocomputing</strong>), 2018<br /> 
<a href='https://www.sciencedirect.com/science/article/pii/S0925231218306209'>[PDF]</a>
<a href='https://youtu.be/g9rf-YFGgbg'>[demo]</a>
<a href='https://github.com/irfanICMLL/Auto_painter'>[code]</a>

</div>
<div class="spanner"></div>
</div>

<div class="paper" id="ICASSP"><img class="paper" src="papers/icassp.png" title="Pixel Level Data Augmentation for Semantic Image Segmentation using Generative Adversarial Networks" />
<div> <strong>Pixel Level Data Augmentation for Semantic Image Segmentation using Generative Adversarial Networks</strong><br />
Shuangting Liu, Jiaqi Zhang, Yuxin Chen,<strong>Yifan Liu</strong>, Zengchang Qin, Tao Wan <br />
IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2019, <alert>[oral]</alert><br /> 
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683590'>[PDF]</a>

</div>
<div class="spanner"></div>
</div>

<div class="paper" id="PAKDD2018"><img class="paper" src="papers/pakdd.png" title="Emotion Classification with Data Augmentation Using Generative Adversarial Networks" />
<div> <strong>Emotion Classification with Data Augmentation Using Generative Adversarial Networks</strong><br />
Xinyue Zhu*, <strong>Yifan Liu*</strong>, Zengchang Qin, and Jiahong Li<br />  
Pacific-Asia Conference on Knowledge Discovery and Data Mining (<strong>PAKDD</strong>), 2018, <alert>[oral]</alert><br /> 
<a href='https://arxiv.org/pdf/1711.00648v5.pdf'>[PDF]</a>
<a href='https://github.com/SharonZhu/Data-augmentation-using-GAN'>[code]</a>
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="IEA/AIE"><img class="paper" src="papers/ieaaie.png" title="Stock Volatility Prediction Using Recurrent Neural Networks with Sentiment Analysis" />
<div> <strong>Stock Volatility Prediction Using Recurrent Neural Networks with Sentiment Analysis</strong><br />
<strong>Yifan Liu</strong>, Zengchang Qin, Pengyu Li, and Tao Wan <br />
International Conference on Industrial, Engineering & Other Applications of Applied Intelligent Systems (<strong>IEA/AIE</strong>), 2017<alert>[oral]</alert><br />
<a href='https://arxiv.org/pdf/1705.02447.pdf'>[PDF]</a>
<a href='https://github.com/irfanICMLL/EMM-for-stock-prediction'>[code]</a>

</div>
<div class="spanner"></div>
</div>


<div class="paper" id="pacling"><img class="paper" src="papers/ll.png" title="Logical Parsing from Natural Language Based on a Neural Translation Model" />
<div> <strong>Logical Parsing from Natural Language Based on a Neural Translation Model</strong><br />
<strong>Yifan Liu*</strong>, Liang Li*, Zengchang Qin, Pengyu Li, Tao Wan<br />
Conference of the Pacific Association for Computational Linguistics (<strong>PACLING</strong>), 2017<alert>[oral]</alert><br />
<a href='https://arxiv.org/pdf/1705.03389'>[pdf]</a> <br />
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professional activities</h2>
<div class="paper">
<ul>
<p><strong><font size="5"> Journals</font></p></strong>
<p><font size="5">Neurocomputing, Pattern Recognition, Robotics and Automation Letters</font></p>
<p><strong><font size="5"> Conferences</font></p></strong>
<p><font size="5">IJCAI</font></p>
</ul>
</div>
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Contests</h2>
<div class="paper">
<ul>
<li><strong>AI Edge Contest, on <a href='https://signate.jp/competitions/143/leaderboard'>Semantic segmentation </a> <strong>Rank</strong>: 3/90</li>
<li><strong>“ZhiYin maker” business plan competition,  <strong>Rank</strong>: 2/207.</li>


</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section"><h2>Awards</h2>
<div class="paper">
<li><strong>“The outstanding graduates of Beijing”, 2016</li>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section"><h2>Friends</h2>
<div class="paper">
<a href='https://github.com/tianzhi0549'>Zhi Tian</a> (Adelaide Uni),
<a href='https://tonghe90.github.io/'>Tong He</a> (Adelaide Uni),
<a href='https://changqianyu.me/'>Changqian Yu</a> (HUST),
<a href="https://github.com/sunke123/">Ke Sun</a> (USTC),
<a href="https://github.com/PkuRainBow">Yuhui Yuan</a> (MSRA),
</div>
</div>
</div>


<div style="clear:both;">
<p align="right"><font size="5">Last Updated on 11th Jul, 2019</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>
<div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=ESrHfC12ZPaJA2MDjb1uqzEe7HKxktsmOkRHtb72vGI&cl=ffffff&w=a"></script>
</body>
</html>
